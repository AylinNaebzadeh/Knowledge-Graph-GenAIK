{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-01T14:47:37.566702Z","iopub.status.busy":"2024-10-01T14:47:37.566175Z","iopub.status.idle":"2024-10-01T14:47:37.572815Z","shell.execute_reply":"2024-10-01T14:47:37.571803Z","shell.execute_reply.started":"2024-10-01T14:47:37.566666Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:47:43.562846Z","iopub.status.busy":"2024-10-01T14:47:43.562456Z","iopub.status.idle":"2024-10-01T14:47:58.074170Z","shell.execute_reply":"2024-10-01T14:47:58.073024Z","shell.execute_reply.started":"2024-10-01T14:47:43.562811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gliner\n","  Downloading gliner-0.2.13-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gliner) (2.4.0)\n","Requirement already satisfied: transformers>=4.38.2 in /opt/conda/lib/python3.10/site-packages (from gliner) (4.44.2)\n","Requirement already satisfied: huggingface-hub>=0.21.4 in /opt/conda/lib/python3.10/site-packages (from gliner) (0.25.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gliner) (4.66.4)\n","Collecting onnxruntime (from gliner)\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from gliner) (0.2.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (6.0.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.4->gliner) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->gliner) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->gliner) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->gliner) (3.1.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->gliner) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->gliner) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->gliner) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->gliner) (0.19.1)\n","Collecting coloredlogs (from onnxruntime->gliner)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime->gliner) (24.3.25)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime->gliner) (3.20.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.21.4->gliner) (3.1.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->gliner) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.4->gliner) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.4->gliner) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.4->gliner) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.4->gliner) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->gliner) (1.3.0)\n","Downloading gliner-0.2.13-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, gliner\n","Successfully installed coloredlogs-15.0.1 gliner-0.2.13 humanfriendly-10.0 onnxruntime-1.19.2\n"]}],"source":["!pip install gliner"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:49:04.625787Z","iopub.status.busy":"2024-10-01T14:49:04.624809Z","iopub.status.idle":"2024-10-01T14:50:25.377120Z","shell.execute_reply":"2024-10-01T14:50:25.376010Z","shell.execute_reply.started":"2024-10-01T14:49:04.625741Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44b5f3b124c344bdb465e4ce8545ff83","version_major":2,"version_minor":0},"text/plain":["Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8db778a5c0bc4cb28a6584039aba5892","version_major":2,"version_minor":0},"text/plain":["gliner_config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d39b88cee4ea4042aa9eec0eb2aaa48f","version_major":2,"version_minor":0},"text/plain":["NuZero_token_token_metrics.txt:   0%|          | 0.00/961 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9ac8efdd0894ec8bf34f071c44576f5","version_major":2,"version_minor":0},"text/plain":["zero_shot_performance_unzero_token.png:   0%|          | 0.00/43.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ff54edd73ed406292123ba1ddfb33e9","version_major":2,"version_minor":0},"text/plain":[".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61d37339b2ff449f8212e0a55deffb7f","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/4.05k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2851a15b895d4961ac065d578a33f2f3","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1500aa4d0404119beea5ba3b2e78f43","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa04d62967734da99acea4d2478bbab1","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"479ef0da92694a9bbdb36dbfc619b101","version_major":2,"version_minor":0},"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["from gliner import GLiNER\n","\n","def merge_entities(entities):\n","    if not entities:\n","        return []\n","    merged = []\n","    current = entities[0]\n","    for next_entity in entities[1:]:\n","        if next_entity['label'] == current['label'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n","            current['text'] = text[current['start']: next_entity['end']].strip()\n","            current['end'] = next_entity['end']\n","        else:\n","            merged.append(current)\n","            current = next_entity\n","    # Append the last entity\n","    merged.append(current)\n","    return merged\n","\n","\n","# model = GLiNER.from_pretrained(\"numind/NuNerZero\")\n","model = GLiNER.from_pretrained(\"numind/NuZero_token\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:50:30.294881Z","iopub.status.busy":"2024-10-01T14:50:30.294238Z","iopub.status.idle":"2024-10-01T14:50:31.360974Z","shell.execute_reply":"2024-10-01T14:50:31.360034Z","shell.execute_reply.started":"2024-10-01T14:50:30.294841Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["Fiat => organization\n","Chrysler => company\n","U.S. => location\n","Italian => location\n","Europe => location\n","January 1 => date\n","Chrysler => company\n","Chief Executive => position\n","Sergio Marchionne => person\n"]}],"source":["labels = [\"location\",\"date\",\"person\",\"event\", \"company\", \"organization\", \"position\"]\n","labels = [l.lower() for l in labels]\n","\n","text = \"\"\"Fiat has completed its buyout of Chrysler, making the U.S. business a wholly-owned subsidiary of the Italian\n","carmaker as it gears up to use their combined resources to turn around its loss-making operations in\n","Europe. The company announced on January 1 that it had struck a $4.35 billion deal - cheaper than analysts\n","had expected - to gain full control of Chrysler, ending more than a year of tense talks that had obstructed Chief Executive Sergio Marchionne's efforts to create the\n","world's seventh-largest auto maker.\"\"\"\n","\n","entities = model.predict_entities(text, labels, threshold=0.4)\n","\n","entities = merge_entities(entities)\n","\n","for entity in entities:\n","    print(entity[\"text\"], \"=>\", entity[\"label\"])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:56:57.287559Z","iopub.status.busy":"2024-10-01T14:56:57.286790Z","iopub.status.idle":"2024-10-01T14:57:10.955818Z","shell.execute_reply":"2024-10-01T14:57:10.954839Z","shell.execute_reply.started":"2024-10-01T14:56:57.287517Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.5)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=a72701d090cba19b819481d31a71b087933f5173b098448d16f1e2fd60686d3e\n","  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}],"source":["!pip install wikipedia"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:57:43.174656Z","iopub.status.busy":"2024-10-01T14:57:43.173876Z","iopub.status.idle":"2024-10-01T14:57:57.499532Z","shell.execute_reply":"2024-10-01T14:57:57.498320Z","shell.execute_reply.started":"2024-10-01T14:57:43.174617Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting langchain\n","  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n","  Downloading langchain_core-0.3.7-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n","Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.6->langchain)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (2.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n","Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.7-py3-none-any.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: packaging, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.8.3 requires cubinlinker, which is not installed.\n","cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires ptxcompiler, which is not installed.\n","cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\n","ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.3.1 langchain-core-0.3.7 langchain-text-splitters-0.3.0 langsmith-0.1.129 packaging-24.1\n"]}],"source":["!pip install langchain"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:57:27.588158Z","iopub.status.busy":"2024-10-01T14:57:27.587742Z","iopub.status.idle":"2024-10-01T14:57:27.764383Z","shell.execute_reply":"2024-10-01T14:57:27.763610Z","shell.execute_reply.started":"2024-10-01T14:57:27.588118Z"},"trusted":true},"outputs":[],"source":["import wikipedia\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:58:42.645451Z","iopub.status.busy":"2024-10-01T14:58:42.645034Z","iopub.status.idle":"2024-10-01T14:58:56.809327Z","shell.execute_reply":"2024-10-01T14:58:56.808314Z","shell.execute_reply.started":"2024-10-01T14:58:42.645414Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting langchain-community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.1)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.7)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.129)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (2.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Installing collected packages: pydantic-settings, langchain-community\n","Successfully installed langchain-community-0.3.1 pydantic-settings-2.5.2\n"]}],"source":["!pip install -U langchain-community"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:00:23.542327Z","iopub.status.busy":"2024-10-01T15:00:23.541662Z","iopub.status.idle":"2024-10-01T15:00:35.469454Z","shell.execute_reply":"2024-10-01T15:00:35.468307Z","shell.execute_reply.started":"2024-10-01T15:00:23.542278Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.7.0\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:59:14.013889Z","iopub.status.busy":"2024-10-01T14:59:14.012955Z","iopub.status.idle":"2024-10-01T14:59:14.025880Z","shell.execute_reply":"2024-10-01T14:59:14.024632Z","shell.execute_reply.started":"2024-10-01T14:59:14.013847Z"},"trusted":true},"outputs":[],"source":["from langchain.document_loaders import WikipediaLoader\n","from langchain.text_splitter import CharacterTextSplitter"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:02:31.904650Z","iopub.status.busy":"2024-10-01T15:02:31.903877Z","iopub.status.idle":"2024-10-01T15:02:50.338402Z","shell.execute_reply":"2024-10-01T15:02:50.337494Z","shell.execute_reply.started":"2024-10-01T15:02:31.904610Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 29/29 [00:00<00:00, 179402.38it/s]\n"]}],"source":["raw_documents = WikipediaLoader(query=\"Large Language Model\").load()\n","\n","# Define chunking strategy\n","text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n","    chunk_size=1000, chunk_overlap=20\n",")\n","# Chunk the document\n","documents = text_splitter.split_documents(raw_documents)\n","for d in tqdm(documents):\n","    del d.metadata[\"summary\"]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:02:53.109314Z","iopub.status.busy":"2024-10-01T15:02:53.108904Z","iopub.status.idle":"2024-10-01T15:02:53.114735Z","shell.execute_reply":"2024-10-01T15:02:53.113723Z","shell.execute_reply.started":"2024-10-01T15:02:53.109277Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["https://en.wikipedia.org/wiki/Large_language_model\n","https://en.wikipedia.org/wiki/Language_model\n","https://en.wikipedia.org/wiki/Language_model\n","https://en.wikipedia.org/wiki/Language_model\n","https://en.wikipedia.org/wiki/Claude_(language_model)\n","https://en.wikipedia.org/wiki/Llama_(language_model)\n","https://en.wikipedia.org/wiki/BLOOM_(language_model)\n","https://en.wikipedia.org/wiki/T5_(language_model)\n","https://en.wikipedia.org/wiki/T5_(language_model)\n","https://en.wikipedia.org/wiki/BERT_(language_model)\n","https://en.wikipedia.org/wiki/Gemini_(language_model)\n","https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n","https://en.wikipedia.org/wiki/Chinchilla_(language_model)\n","https://en.wikipedia.org/wiki/Prompt_engineering\n","https://en.wikipedia.org/wiki/Foundation_model\n","https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n","https://en.wikipedia.org/wiki/GPT-3\n","https://en.wikipedia.org/wiki/Mistral_AI\n","https://en.wikipedia.org/wiki/PaLM\n","https://en.wikipedia.org/wiki/Modeling_language\n","https://en.wikipedia.org/wiki/Perplexity_AI\n","https://en.wikipedia.org/wiki/Model_collapse\n","https://en.wikipedia.org/wiki/Model_collapse\n","https://en.wikipedia.org/wiki/GPT-4o\n","https://en.wikipedia.org/wiki/ChatGPT\n","https://en.wikipedia.org/wiki/Jais_(language_model)\n","https://en.wikipedia.org/wiki/Stochastic_parrot\n","https://en.wikipedia.org/wiki/Open-source_artificial_intelligence\n","https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n"]}],"source":["for doc in documents:\n","    print(doc.metadata['source'])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:07:10.032755Z","iopub.status.busy":"2024-10-01T15:07:10.031839Z","iopub.status.idle":"2024-10-01T15:07:10.039480Z","shell.execute_reply":"2024-10-01T15:07:10.038473Z","shell.execute_reply.started":"2024-10-01T15:07:10.032713Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["https://en.wikipedia.org/wiki/Large_language_model\n","https://en.wikipedia.org/wiki/Language_model\n","https://en.wikipedia.org/wiki/Claude_(language_model)\n","https://en.wikipedia.org/wiki/Llama_(language_model)\n","https://en.wikipedia.org/wiki/BLOOM_(language_model)\n","https://en.wikipedia.org/wiki/T5_(language_model)\n","https://en.wikipedia.org/wiki/BERT_(language_model)\n","https://en.wikipedia.org/wiki/Gemini_(language_model)\n","https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n","https://en.wikipedia.org/wiki/Chinchilla_(language_model)\n","https://en.wikipedia.org/wiki/Prompt_engineering\n","https://en.wikipedia.org/wiki/Foundation_model\n","https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n","https://en.wikipedia.org/wiki/GPT-3\n","https://en.wikipedia.org/wiki/Mistral_AI\n","https://en.wikipedia.org/wiki/PaLM\n","https://en.wikipedia.org/wiki/Modeling_language\n","https://en.wikipedia.org/wiki/Perplexity_AI\n","https://en.wikipedia.org/wiki/Model_collapse\n","https://en.wikipedia.org/wiki/GPT-4o\n","https://en.wikipedia.org/wiki/ChatGPT\n","https://en.wikipedia.org/wiki/Jais_(language_model)\n","https://en.wikipedia.org/wiki/Stochastic_parrot\n","https://en.wikipedia.org/wiki/Open-source_artificial_intelligence\n","https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n"]}],"source":["# Step 1: Use a set to track seen sources\n","unique_documents = []\n","seen_sources = set()\n","\n","# Step 2: Iterate through the documents and store only unique sources\n","for doc in documents:\n","    source = doc.metadata['source']\n","    if source not in seen_sources:\n","        unique_documents.append(doc)\n","        seen_sources.add(source)\n","\n","# Step 3: Iterate through unique documents and print their sources\n","for doc in unique_documents:\n","    print(doc.metadata['source'])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:21:15.898846Z","iopub.status.busy":"2024-10-01T15:21:15.898055Z","iopub.status.idle":"2024-10-01T15:21:15.904469Z","shell.execute_reply":"2024-10-01T15:21:15.903438Z","shell.execute_reply.started":"2024-10-01T15:21:15.898808Z"},"trusted":true},"outputs":[],"source":["labels = [\n","    \"model\",            # Large Language Models (e.g., GPT-4, BERT, T5, LLaMA)\n","    \"organization\",     # Companies or institutions (e.g., OpenAI, Google)\n","    \"person\",           # Key figures in AI/ML (e.g., Sam Altman, Geoffrey Hinton)\n","    \"event\",            # Conferences, events, or milestones (e.g., NeurIPS, ACL)\n","    \"dataset\",          # Datasets used to train models (e.g., Common Crawl)\n","    \"metric\",           # Performance evaluation metrics (e.g., perplexity, accuracy)\n","    \"technology\",       # Techniques and methods (e.g., Transformer, attention mechanism)\n","    \"application\",      # Applications of LLMs (e.g., ChatGPT, translation, summarization)\n","    \"company\",          # AI companies (e.g., DeepMind, Microsoft)\n","    \"position\",         # Job titles or roles (e.g., CEO, researcher)\n","    \"location\",         # Geographical locations (e.g., cities, countries)\n","    \"date\",             # Important dates or time references\n","    \"product\"           # AI products (e.g., cloud platforms, AI tools)\n","]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:21:32.791698Z","iopub.status.busy":"2024-10-01T15:21:32.791309Z","iopub.status.idle":"2024-10-01T15:21:32.796488Z","shell.execute_reply":"2024-10-01T15:21:32.795472Z","shell.execute_reply.started":"2024-10-01T15:21:32.791662Z"},"trusted":true},"outputs":[],"source":["from langchain_text_splitters import RecursiveCharacterTextSplitter"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:32:16.467428Z","iopub.status.busy":"2024-10-01T15:32:16.466343Z","iopub.status.idle":"2024-10-01T15:36:14.615394Z","shell.execute_reply":"2024-10-01T15:36:14.614439Z","shell.execute_reply.started":"2024-10-01T15:32:16.467385Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/25 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Large_language_model\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 1/25 [00:10<04:06, 10.27s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Language_model\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 2/25 [00:13<02:23,  6.24s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Claude_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 3/25 [00:28<03:42, 10.10s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Llama_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 4/25 [00:38<03:35, 10.25s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/BLOOM_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 5/25 [00:42<02:35,  7.80s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/T5_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 6/25 [00:52<02:43,  8.60s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/BERT_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 7/25 [01:03<02:51,  9.54s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Gemini_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 8/25 [01:11<02:32,  8.95s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 9/25 [01:22<02:30,  9.43s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Chinchilla_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 10/25 [01:28<02:09,  8.61s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Prompt_engineering\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 11/25 [01:40<02:11,  9.38s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Foundation_model\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 12/25 [01:49<02:01,  9.32s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 13/25 [01:58<01:51,  9.29s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/GPT-3\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 14/25 [02:07<01:41,  9.27s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Mistral_AI\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 15/25 [02:21<01:45, 10.52s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/PaLM\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 16/25 [02:28<01:27,  9.73s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Modeling_language\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 17/25 [02:42<01:28, 11.02s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Perplexity_AI\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 18/25 [02:53<01:17, 11.01s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Model_collapse\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 19/25 [03:00<00:58,  9.78s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/GPT-4o\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 20/25 [03:11<00:50, 10.17s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/ChatGPT\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▍ | 21/25 [03:19<00:37,  9.43s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Jais_(language_model)\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 22/25 [03:25<00:24,  8.32s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Stochastic_parrot\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 23/25 [03:37<00:18,  9.36s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Open-source_artificial_intelligence\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 24/25 [03:42<00:08,  8.11s/it]"]},{"name":"stdout","output_type":"stream","text":["The document is: https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 25/25 [03:58<00:00,  9.53s/it]\n"]}],"source":["# Define the text splitter with chunking strategy\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=200,\n","    chunk_overlap=20,\n","    separators=[\"\\n\\n\", \"\\n\"]\n",")\n","\n","chunks_entities = []\n","entity_list = []\n","duplicates = set()\n","\n","for doc in tqdm(unique_documents):\n","    print(f\"The document is: {doc.metadata['source']}\\n\")\n","    chunks = text_splitter.split_text(doc.page_content)\n","    for text in chunks:\n","        entities = model.predict_entities(text, labels, threshold=0.7)\n","        entities = merge_entities(entities)\n","        \n","        chunk_entities = set() \n","        for entity in entities:\n","            chunk_entities.add(entity[\"text\"])\n","            \n","            if entity[\"text\"] not in duplicates:\n","                duplicates.add(entity[\"text\"])\n","                entity_list.append((entity[\"text\"], \"=>\", entity[\"label\"]))\n","        \n","        chunks_entities.append(list(chunk_entities))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:41:35.919138Z","iopub.status.busy":"2024-10-01T15:41:35.918353Z","iopub.status.idle":"2024-10-01T15:41:35.926298Z","shell.execute_reply":"2024-10-01T15:41:35.925319Z","shell.execute_reply.started":"2024-10-01T15:41:35.919098Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[['LLM', 'language models', 'large language model'],\n"," ['human language corpora',\n","  'August 2024',\n","  'transformer-based architecture',\n","  'artificial neural networks',\n","  'data',\n","  'models']]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["chunks_entities[:2]"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:41:58.798114Z","iopub.status.busy":"2024-10-01T15:41:58.797188Z","iopub.status.idle":"2024-10-01T15:41:58.804251Z","shell.execute_reply":"2024-10-01T15:41:58.803050Z","shell.execute_reply.started":"2024-10-01T15:41:58.798070Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\nThe model feeds this relevant retrieved information into the LLM via prompt engineering of the user's original query. Newer implementations (as of 2023) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains, and using memory and self-improvement to learn from previous retrievals.\""]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["chunks[9]"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:42:11.857179Z","iopub.status.busy":"2024-10-01T15:42:11.856775Z","iopub.status.idle":"2024-10-01T15:42:11.863920Z","shell.execute_reply":"2024-10-01T15:42:11.862887Z","shell.execute_reply.started":"2024-10-01T15:42:11.857142Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[('large language model', '=>', 'model'),\n"," ('LLM', '=>', 'model'),\n"," ('language models', '=>', 'model'),\n"," ('August 2024', '=>', 'date')]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["entity_list[:4]"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:53:58.427908Z","iopub.status.busy":"2024-10-01T15:53:58.426993Z","iopub.status.idle":"2024-10-01T15:53:58.442919Z","shell.execute_reply":"2024-10-01T15:53:58.441622Z","shell.execute_reply.started":"2024-10-01T15:53:58.427868Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 612/612 [00:00<00:00, 623491.39it/s]\n"]}],"source":["models = []\n","orgs = []\n","persons = []\n","events = []\n","datasets = []\n","metrics = []\n","techs = []\n","apps = []\n","comps = []\n","poses = []\n","locs = []\n","dates = []\n","prods = []\n","\n","for e in tqdm(entity_list):\n","    s,p, o = e\n","    if o == 'model':\n","        models.append(s.lower())\n","    elif o == 'organization':\n","        orgs.append(s.lower())\n","    elif o == 'person':\n","        persons.append(s.lower())\n","    elif o == 'event':\n","        events.append(s.lower())\n","    elif o == 'dataset':\n","        datasets.append(s.lower())\n","    elif o == 'metric':\n","        metrics.append(s.lower())\n","    elif o == 'technology':\n","        techs.append(s.lower())\n","    elif o == 'application':\n","        apps.append(s.lower())\n","    elif o == 'company':\n","        poses.append(s.lower())\n","    elif o == 'position':\n","        orgs.append(s.lower())\n","    elif o == 'location':\n","        locs.append(s.lower())\n","    elif o == 'date':\n","        dates.append(s.lower())\n","    elif o == 'product':\n","        prods.append(s.lower())"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T15:56:13.028552Z","iopub.status.busy":"2024-10-01T15:56:13.028111Z","iopub.status.idle":"2024-10-01T15:56:13.036727Z","shell.execute_reply":"2024-10-01T15:56:13.035732Z","shell.execute_reply.started":"2024-10-01T15:56:13.028509Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(167, 59, 45, 16, 57, 27, 99, 23, 0, 20, 19, 57, 23)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["len(models), len(orgs), len(persons), len(events), len(datasets), len(metrics), len(techs), len(apps), len(comps), len(poses), len(locs), len(dates), len(prods) "]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T16:12:48.430602Z","iopub.status.busy":"2024-10-01T16:12:48.429945Z","iopub.status.idle":"2024-10-01T16:13:03.245640Z","shell.execute_reply":"2024-10-01T16:13:03.244643Z","shell.execute_reply.started":"2024-10-01T16:12:48.430561Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting litellm\n","  Downloading litellm-1.48.7-py3-none-any.whl.metadata (32 kB)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from litellm) (3.9.5)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from litellm) (8.1.7)\n","Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (7.0.0)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from litellm) (3.1.4)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (4.22.0)\n","Collecting openai>=1.45.0 (from litellm)\n","  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (2.9.2)\n","Requirement already satisfied: python-dotenv>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (1.0.1)\n","Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (2.32.3)\n","Requirement already satisfied: tiktoken>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from litellm) (0.7.0)\n","Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from litellm) (0.19.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm) (3.19.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.18.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (4.4.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (0.27.0)\n","Collecting jiter<1,>=0.4.0 (from openai>=1.45.0->litellm)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai>=1.45.0->litellm) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->litellm) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2024.8.30)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken>=0.7.0->litellm) (2024.5.15)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->litellm) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->litellm) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->litellm) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->litellm) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->litellm) (4.0.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers->litellm) (0.25.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.45.0->litellm) (1.2.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.45.0->litellm) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.45.0->litellm) (0.14.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n","Downloading litellm-1.48.7-py3-none-any.whl (7.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, openai, litellm\n","Successfully installed jiter-0.5.0 litellm-1.48.7 openai-1.50.2\n"]}],"source":["!pip install litellm"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T16:13:07.395073Z","iopub.status.busy":"2024-10-01T16:13:07.394148Z","iopub.status.idle":"2024-10-01T16:13:09.900705Z","shell.execute_reply":"2024-10-01T16:13:09.899686Z","shell.execute_reply.started":"2024-10-01T16:13:07.395025Z"},"trusted":true},"outputs":[],"source":["from litellm import completion\n","from typing import List\n","import json"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T16:13:30.895219Z","iopub.status.busy":"2024-10-01T16:13:30.894431Z","iopub.status.idle":"2024-10-01T16:13:30.900821Z","shell.execute_reply":"2024-10-01T16:13:30.899819Z","shell.execute_reply.started":"2024-10-01T16:13:30.895179Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2024\n","\n","Transformer architecture\n","\n","recurrent neural network variants\n","\n","Mamba\n"]}],"source":["def format_entities(ent_list:List[str]) -> str:\n","    return \"\\n\\n\".join([e for e in ent_list])\n","\n","print(format_entities(chunks_entities[9]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["system_message = \"\"\"Extract all the relationships between the following entities ONLY based on the given context. \n","Return a list of JSON objects. For example:\n","\n","<Examples>\n","    [{{\"subject\": \"John\", \"relationship\": \"lives in\", \"object\": \"US\"}},\n","    {{\"subject\": \"Eifel towel\", \"relationship\": \"is located in\", \"object\": \"Paris\"}},\n","    {{\"subject\": \"Hayao Miyazaki\", \"relationship\": \"is\", \"object\": \"Japanese animator\"}}]\n","</Examples>\n","\n","- ONLY return triples and nothing else. None of 'subject', 'relationship' and 'object' can be empty.\n","\n","Entities: \\n\\n{entities}\n","\n","\"\"\"\n","# example for a particular set of entities\n","i = 3\n","\n","ents = format_entities(chunks_entities[i])\n","text = chunks[i]\n","\n","user_message = \"Context: {text}\\n\\nTriples:\"\n","response = completion(\n","  # api_key=\"\" \n","  model=\"gpt-3.5-turbo\",\n","  messages=[{\"content\": system_message.format(entities=ents),\"role\": \"system\"}, {\"content\": user_message.format(text=text),\"role\": \"user\"}],\n","  max_tokens=1000,\n","  format = \"json\"\n",")\n","\n","triples = json.loads(response.choices[0].message.content)\n","triples"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
