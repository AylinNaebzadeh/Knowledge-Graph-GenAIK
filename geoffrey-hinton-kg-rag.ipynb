{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-13T17:09:59.263228Z","iopub.status.busy":"2024-10-13T17:09:59.262608Z","iopub.status.idle":"2024-10-13T17:09:59.637073Z","shell.execute_reply":"2024-10-13T17:09:59.636162Z","shell.execute_reply.started":"2024-10-13T17:09:59.263187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/genaik2025-aylin/results_clean_v2.txt\n","/kaggle/input/genaik2025-aylin/summary_clean_v2.txt\n","/kaggle/input/genaik2025-aylin/cypher_query_v2.txt\n","/kaggle/input/genaik2025-aylin/summary_clean.txt\n","/kaggle/input/genaik2025-aylin/results_clean.txt\n","/kaggle/input/genaik2025-aylin/cypher_query.txt\n","/kaggle/input/genaik2025-aylin/neo4j_query_table_data_2024-10-12.csv\n","/kaggle/input/genaik2025-aylin/Geoffrey_Hinton_KG.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Sources:\n","- https://github.com/sunnysavita10/Generative-AI-Indepth-Basic-to-Advance/blob/main/RAG%20with%20Knowledge%20Graph%20Neo4j/RAG_With_Knowledge_graph(Neo4j).ipynb\n","- https://www.youtube.com/watch?v=9ZBamhWPSKg"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:10:21.305875Z","iopub.status.busy":"2024-10-13T17:10:21.305407Z","iopub.status.idle":"2024-10-13T17:11:05.641693Z","shell.execute_reply":"2024-10-13T17:11:05.640430Z","shell.execute_reply.started":"2024-10-13T17:10:21.305840Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.8.3 requires cubinlinker, which is not installed.\n","cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires ptxcompiler, which is not installed.\n","cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n","ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install --upgrade --quiet langchain_groq\n","!pip install --upgrade --quiet sentence-transformers\n","!pip install --upgrade --quiet  langchain langchain-community  langchain-experimental neo4j "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:11:05.644239Z","iopub.status.busy":"2024-10-13T17:11:05.643900Z","iopub.status.idle":"2024-10-13T17:11:07.224633Z","shell.execute_reply":"2024-10-13T17:11:07.223712Z","shell.execute_reply.started":"2024-10-13T17:11:05.644202Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["from langchain_core.runnables import (\n","    RunnableBranch,\n","    RunnableLambda,\n","    RunnableParallel,\n","    RunnablePassthrough,\n",")\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.prompts.prompt import PromptTemplate\n","from typing import Tuple, List, Optional\n","from langchain_core.messages import AIMessage, HumanMessage\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import ConfigurableField\n","from neo4j import GraphDatabase\n","from langchain_community.vectorstores import Neo4jVector\n","from langchain_community.graphs import Neo4jGraph\n","from getpass import getpass\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_groq import ChatGroq\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n","from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:11:07.227721Z","iopub.status.busy":"2024-10-13T17:11:07.226842Z","iopub.status.idle":"2024-10-13T17:11:22.833755Z","shell.execute_reply":"2024-10-13T17:11:22.833014Z","shell.execute_reply.started":"2024-10-13T17:11:07.227684Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["NEO4J_CONNECTION_URL ·········································\n","NEO4J_USER ·····\n","NEO4J_PASSWORD ···········································\n"]}],"source":["neo4j_url = getpass(\"NEO4J_CONNECTION_URL\") \n","neo4j_user = getpass(\"NEO4J_USER\") \n","neo4j_password = getpass(\"NEO4J_PASSWORD\") \n","graph = Neo4jGraph(neo4j_url, neo4j_user, neo4j_password)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:11:22.836369Z","iopub.status.busy":"2024-10-13T17:11:22.835676Z","iopub.status.idle":"2024-10-13T17:11:27.002686Z","shell.execute_reply":"2024-10-13T17:11:27.001906Z","shell.execute_reply.started":"2024-10-13T17:11:22.836320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Groq API key:  ························································\n"]}],"source":["if \"GROQ_API_KEY\" not in os.environ: \n","    os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API key: \")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:11:30.617763Z","iopub.status.busy":"2024-10-13T17:11:30.616960Z","iopub.status.idle":"2024-10-13T17:12:04.277156Z","shell.execute_reply":"2024-10-13T17:12:04.276449Z","shell.execute_reply.started":"2024-10-13T17:11:30.617726Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2407877103.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  hf = HuggingFaceEmbeddings(\n","/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97a25fdaa832444aa3a932e6ec25071d","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ddd2c886e694532bbc6f18d5dc73091","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c6e21dfec0a4dbf8df0bc984de4a135","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b64a00188d934906a45eb8d9bd503b5d","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9e214cb81de49d4bba023344094a2d7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"984432e0cde646fd81d69b0df523d8da","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cde4b45ba8c841d79fcc6e4d674b73bc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cae359661ba4ff681f8729947ebb6dc","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bba9dd8a4143441bb5f663796c438f1b","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4def677d16004bf69eb62016cb302df8","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9492f20f93648d98b5f00c124fb42e2","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n","model_kwargs = {'device': 'cpu'}\n","encode_kwargs = {'normalize_embeddings': False}\n","hf = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:07.239879Z","iopub.status.busy":"2024-10-13T17:12:07.239123Z","iopub.status.idle":"2024-10-13T17:12:07.244709Z","shell.execute_reply":"2024-10-13T17:12:07.243859Z","shell.execute_reply.started":"2024-10-13T17:12:07.239841Z"},"trusted":true},"outputs":[],"source":["os.environ[\"NEO4J_URI\"] = neo4j_url\n","os.environ[\"NEO4J_USERNAME\"] = neo4j_user\n","os.environ[\"NEO4J_PASSWORD\"] = neo4j_password"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:10.320999Z","iopub.status.busy":"2024-10-13T17:12:10.320204Z","iopub.status.idle":"2024-10-13T17:12:12.352367Z","shell.execute_reply":"2024-10-13T17:12:12.351399Z","shell.execute_reply.started":"2024-10-13T17:12:10.320959Z"},"trusted":true},"outputs":[],"source":["vector_index = Neo4jVector.from_existing_graph(\n","    hf,\n","    search_type=\"hybrid\",\n","    node_label=\"Document\",\n","    text_node_properties=[\"text\"],\n","    embedding_node_property=\"embedding\"\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:16.156797Z","iopub.status.busy":"2024-10-13T17:12:16.155739Z","iopub.status.idle":"2024-10-13T17:12:16.163615Z","shell.execute_reply":"2024-10-13T17:12:16.162520Z","shell.execute_reply.started":"2024-10-13T17:12:16.156754Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<langchain_community.vectorstores.neo4j_vector.Neo4jVector at 0x7890da9116f0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["vector_index"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:20.645301Z","iopub.status.busy":"2024-10-13T17:12:20.644628Z","iopub.status.idle":"2024-10-13T17:12:20.916405Z","shell.execute_reply":"2024-10-13T17:12:20.915501Z","shell.execute_reply.started":"2024-10-13T17:12:20.645258Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:23.170520Z","iopub.status.busy":"2024-10-13T17:12:23.169839Z","iopub.status.idle":"2024-10-13T17:12:23.175827Z","shell.execute_reply":"2024-10-13T17:12:23.174919Z","shell.execute_reply.started":"2024-10-13T17:12:23.170478Z"},"trusted":true},"outputs":[],"source":["# Extract entities from text\n","class Entities(BaseModel):\n","    \"\"\"Identifying information about entities.\"\"\"\n","\n","    names: List[str] = Field(\n","        ...,\n","        description=\"All the award, birthPlace, characteristics, date, degree, institution, invention, nationality, person, relation, role and important entities that \"\n","        \"appear in the text\",\n","    )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:25.401648Z","iopub.status.busy":"2024-10-13T17:12:25.400803Z","iopub.status.idle":"2024-10-13T17:12:25.406399Z","shell.execute_reply":"2024-10-13T17:12:25.405498Z","shell.execute_reply.started":"2024-10-13T17:12:25.401609Z"},"trusted":true},"outputs":[],"source":["prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are extracting oaward, birthPlace, characteristics, date, degree, institution, invention, nationality, person, relation, role and important entities from the text.\",\n","        ),\n","        (\n","            \"human\",\n","            \"Use the given format to extract information from the following \"\n","            \"input: {question}\",\n","        ),\n","    ]\n",")\n","   "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:27.378813Z","iopub.status.busy":"2024-10-13T17:12:27.378017Z","iopub.status.idle":"2024-10-13T17:12:27.471180Z","shell.execute_reply":"2024-10-13T17:12:27.470457Z","shell.execute_reply.started":"2024-10-13T17:12:27.378773Z"},"trusted":true},"outputs":[],"source":["llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:29.039416Z","iopub.status.busy":"2024-10-13T17:12:29.038593Z","iopub.status.idle":"2024-10-13T17:12:29.045215Z","shell.execute_reply":"2024-10-13T17:12:29.044308Z","shell.execute_reply.started":"2024-10-13T17:12:29.039371Z"},"trusted":true},"outputs":[],"source":["entity_chain = prompt | llm.with_structured_output(Entities)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:30.657126Z","iopub.status.busy":"2024-10-13T17:12:30.655903Z","iopub.status.idle":"2024-10-13T17:12:31.089449Z","shell.execute_reply":"2024-10-13T17:12:31.088484Z","shell.execute_reply.started":"2024-10-13T17:12:30.657068Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Geoffrey Hinton']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["entity_chain.invoke({\"question\": \"Where was Geoffrey Hinton born?\"}).names"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T17:12:34.463794Z","iopub.status.busy":"2024-10-13T17:12:34.463051Z","iopub.status.idle":"2024-10-13T17:12:34.469256Z","shell.execute_reply":"2024-10-13T17:12:34.468409Z","shell.execute_reply.started":"2024-10-13T17:12:34.463755Z"},"trusted":true},"outputs":[],"source":["def generate_full_text_query(input: str) -> str:\n","    \"\"\"\n","    Generate a full-text search quesry for a given input string.\n","    \n","    This function constructs a query string suitable for a full-text search.\n","    It processes the input string by splitting it into words and appending a\n","    similiarity threshold (~2 changed characters) to each word, then combines\n","    them using the AND operator. Useful for mapping entities from user questions\n","    to database values, and allows for some misspelings.\n","    \"\"\"\n","    full_text_query = \"\"\n","    words = [el for el in remove_lucene_chars(input).split() if el]\n","    for word in words[:-1]:\n","        full_text_query += f\" {word}~2 AND\"\n","    full_text_query += f\" {words[-1]}~2\"\n","    return full_text_query.strip()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:31:17.800831Z","iopub.status.busy":"2024-10-13T18:31:17.800476Z","iopub.status.idle":"2024-10-13T18:31:17.806996Z","shell.execute_reply":"2024-10-13T18:31:17.806110Z","shell.execute_reply.started":"2024-10-13T18:31:17.800796Z"},"trusted":true},"outputs":[],"source":["def structured_retriever(question: str) -> str:\n","    result = \"\"\n","    entities = entity_chain.invoke({\"question\": question})\n","    for entity in entities.names:\n","        response = graph.query(\n","            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n","            YIELD node,score\n","            CALL {\n","              WITH node\n","              MATCH (node)-[r:!MENTIONS]->(neighbor)\n","              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n","              UNION ALL\n","              WITH node\n","              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n","              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n","            }\n","            RETURN output LIMIT 50\n","            \"\"\",\n","            {\"query\": generate_full_text_query(entity)},\n","        )\n","        result += \"\\n\".join([el['output'] for el in response])\n","    return result"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:31:02.596679Z","iopub.status.busy":"2024-10-13T18:31:02.596276Z","iopub.status.idle":"2024-10-13T18:31:04.524806Z","shell.execute_reply":"2024-10-13T18:31:04.523910Z","shell.execute_reply.started":"2024-10-13T18:31:02.596641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Node properties:\n","birthPlace {id: STRING, entityId: INTEGER}\n","person {id: STRING, entityId: INTEGER}\n","institution {id: STRING, entityId: INTEGER}\n","role {id: STRING, entityId: INTEGER}\n","award {id: STRING, entityId: INTEGER}\n","nationality {id: STRING, entityId: INTEGER}\n","invention {id: STRING, entityId: INTEGER}\n","characteristics {id: STRING, entityId: INTEGER}\n","date {id: STRING, entityId: INTEGER}\n","relation {id: STRING, entityId: INTEGER}\n","degree {id: STRING, entityId: INTEGER}\n","Relationship properties:\n","\n","The relationships:\n","(:person)-[:bornIn]->(:birthPlace)\n","(:person)-[:earnedDegreeFrom]->(:institution)\n","(:person)-[:earnedDegree]->(:degree)\n","(:person)-[:worksAt]->(:institution)\n","(:person)-[:developed]->(:invention)\n","(:person)-[:collaboratedWith]->(:person)\n","(:person)-[:collaboratedWith]->(:institution)\n","(:person)-[:hasAward]->(:award)\n","(:person)-[:bornAt]->(:date)\n","(:person)-[:hasNationality]->(:nationality)\n","(:person)-[:hasRole]->(:role)\n","(:person)-[:coFounded]->(:institution)\n","(:person)-[:coInventing]->(:invention)\n","(:person)-[:is]->(:relation)\n","(:person)-[:was]->(:role)\n","(:person)-[:invented]->(:invention)\n","(:person)-[:coAuthored]->(:person)\n","(:person)-[:hasStudent]->(:person)\n","(:person)-[:workedWith]->(:institution)\n","(:person)-[:workedWith]->(:invention)\n","(:person)-[:hasRelation]->(:person)\n","(:person)-[:advocates]->(:characteristics)\n","(:institution)-[:earnedDegreeFrom]->(:degree)\n","(:invention)-[:developed]->(:invention)\n","(:invention)-[:characteristics]->(:characteristics)\n"]}],"source":["graph.refresh_schema()\n","print(graph.schema)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:31:21.764568Z","iopub.status.busy":"2024-10-13T18:31:21.764217Z","iopub.status.idle":"2024-10-13T18:31:22.790858Z","shell.execute_reply":"2024-10-13T18:31:22.789922Z","shell.execute_reply.started":"2024-10-13T18:31:21.764536Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Geoffrey Hinton - bornIn -> London\n","Geoffrey Hinton - worksAt -> University College London\n","Geoffrey Hinton - worksAt -> Carnegie Mellon University\n","Geoffrey Hinton - worksAt -> University of Toronto\n","Geoffrey Hinton - worksAt -> Vector Institute\n","Geoffrey Hinton - worksAt -> Google Brain\n","Geoffrey Hinton - worksAt -> University of California, San Diego\n","Geoffrey Hinton - hasRole -> pursuit of knowledge and innovation\n","Geoffrey Hinton - hasRole -> advisory roles\n","Geoffrey Hinton - hasRole -> research\n","Geoffrey Hinton - hasRole -> cognitive psychologist and computer scientist\n","Geoffrey Hinton - hasRole -> advisory role\n","Geoffrey Hinton - coAuthored -> Ronald J. Williams\n","Geoffrey Hinton - coAuthored -> David Rumelhart\n","Geoffrey Hinton - developed -> mixtures of experts\n","Geoffrey Hinton - developed -> neural networks\n","Geoffrey Hinton - developed -> distributed representations\n","Geoffrey Hinton - developed -> time delay neural networks\n","Geoffrey Hinton - developed -> AI applications\n","Geoffrey Hinton - developed -> the product of experts\n","Geoffrey Hinton - developed -> Helmholtz machines\n","Geoffrey Hinton - invented -> Boltzmann machine\n","Geoffrey Hinton - collaboratedWith -> Richard Zemel\n","Geoffrey Hinton - collaboratedWith -> John J. Hopfield\n","Geoffrey Hinton - collaboratedWith -> Vector Institute\n","Geoffrey Hinton - collaboratedWith -> Alex Krizhevsky\n","Geoffrey Hinton - collaboratedWith -> Yann LeCun\n","Geoffrey Hinton - collaboratedWith -> Brendan Frey\n","Geoffrey Hinton - collaboratedWith -> Yoshua Bengio\n","Geoffrey Hinton - collaboratedWith -> Ruslan Salakhutdinov\n","Geoffrey Hinton - coFounded -> Vector Institute\n","Geoffrey Hinton - hasAward -> Nobel Prize in Physics\n","Geoffrey Hinton - hasAward -> Turing Award\n","Geoffrey Hinton - hasAward -> Rumelhart Prize\n","Geoffrey Hinton - hasAward -> Princess of Asturias Award\n","Geoffrey Hinton - hasAward -> IEEE Frank Rosenblatt Award\n","Geoffrey Hinton - bornAt -> December 6, 1947\n","Geoffrey Hinton - hasNationality -> British-Canadian\n","Geoffrey Hinton - hasStudent -> Ilya Sutskever\n","Geoffrey Hinton - hasStudent -> Yann LeCun\n","Geoffrey Hinton - earnedDegreeFrom -> University of Cambridge\n","Geoffrey Hinton - earnedDegree -> experimental psychology\n","Geoffrey Hinton - earnedDegree -> Ph.D\n","Geoffrey Hinton - workedWith -> field of artificial intelligence\n","Geoffrey Hinton - workedWith -> Google Brain\n","Geoffrey Hinton - workedWith -> Stanford University\n","Geoffrey Hinton - hasRelation -> Mary Everest Boole\n","Geoffrey Hinton - hasRelation -> George Boole\n","Geoffrey Hinton - advocates -> responsible AI practices\n","Geoffrey Hinton - advocates -> ethical implications of advanced technologies\n"]}],"source":["print(structured_retriever(\"Where was Geoffrey Hinton born\"))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:32:23.041899Z","iopub.status.busy":"2024-10-13T18:32:23.041090Z","iopub.status.idle":"2024-10-13T18:32:23.046670Z","shell.execute_reply":"2024-10-13T18:32:23.045751Z","shell.execute_reply.started":"2024-10-13T18:32:23.041857Z"},"trusted":true},"outputs":[],"source":["def retriever(question: str):\n","    print(f\"Search query: {question}\")\n","    structured_data = structured_retriever(question)\n","    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n","    final_data = f\"\"\"Structured data:\n","{structured_data}\n","Unstructured data:\n","{\"#Document \". join(unstructured_data)}\n","    \"\"\"\n","    return final_data"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:32:35.516354Z","iopub.status.busy":"2024-10-13T18:32:35.515954Z","iopub.status.idle":"2024-10-13T18:32:35.520568Z","shell.execute_reply":"2024-10-13T18:32:35.519706Z","shell.execute_reply.started":"2024-10-13T18:32:35.516318Z"},"trusted":true},"outputs":[],"source":["_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n","in its original language.\n","Chat History:\n","{chat_history}\n","Follow Up Input: {question}\n","Standalone question:\"\"\""]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:32:46.579593Z","iopub.status.busy":"2024-10-13T18:32:46.579211Z","iopub.status.idle":"2024-10-13T18:32:46.583951Z","shell.execute_reply":"2024-10-13T18:32:46.583046Z","shell.execute_reply.started":"2024-10-13T18:32:46.579558Z"},"trusted":true},"outputs":[],"source":["CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:32:57.540999Z","iopub.status.busy":"2024-10-13T18:32:57.540349Z","iopub.status.idle":"2024-10-13T18:32:57.546282Z","shell.execute_reply":"2024-10-13T18:32:57.545346Z","shell.execute_reply.started":"2024-10-13T18:32:57.540956Z"},"trusted":true},"outputs":[],"source":["def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n","    buffer = []\n","    for human, ai in chat_history:\n","        buffer.append(HumanMessage(content=human))\n","        buffer.append(AIMessage(content=ai))\n","    return buffer"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:40:01.316772Z","iopub.status.busy":"2024-10-13T18:40:01.316345Z","iopub.status.idle":"2024-10-13T18:40:01.343828Z","shell.execute_reply":"2024-10-13T18:40:01.342973Z","shell.execute_reply.started":"2024-10-13T18:40:01.316716Z"},"trusted":true},"outputs":[],"source":["_search_query = RunnableBranch(\n","    # If input includes chat_history, we condense it with the follow-up question\n","    (\n","        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n","            run_name=\"HasChatHistoryCheck\"\n","        ),  # Condense follow-up question and chat into a standalone_question\n","        RunnablePassthrough.assign(\n","            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n","        )\n","        | CONDENSE_QUESTION_PROMPT\n","        | ChatGroq(temperature=0)\n","        | StrOutputParser(),\n","    ),\n","    # Else, we have no chat history, so just pass through the question\n","    RunnableLambda(lambda x : x[\"question\"]),\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:40:18.571382Z","iopub.status.busy":"2024-10-13T18:40:18.570779Z","iopub.status.idle":"2024-10-13T18:40:18.575389Z","shell.execute_reply":"2024-10-13T18:40:18.574424Z","shell.execute_reply.started":"2024-10-13T18:40:18.571340Z"},"trusted":true},"outputs":[],"source":["template = \"\"\"Answer the question based only on the following context:\n","{context}\n","\n","Question: {question}\n","Use natural language and be concise.\n","Answer:\"\"\""]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:40:28.126382Z","iopub.status.busy":"2024-10-13T18:40:28.125548Z","iopub.status.idle":"2024-10-13T18:40:28.130787Z","shell.execute_reply":"2024-10-13T18:40:28.129704Z","shell.execute_reply.started":"2024-10-13T18:40:28.126343Z"},"trusted":true},"outputs":[],"source":["prompt = ChatPromptTemplate.from_template(template)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:40:39.035983Z","iopub.status.busy":"2024-10-13T18:40:39.035065Z","iopub.status.idle":"2024-10-13T18:40:39.040676Z","shell.execute_reply":"2024-10-13T18:40:39.039818Z","shell.execute_reply.started":"2024-10-13T18:40:39.035943Z"},"trusted":true},"outputs":[],"source":["chain = (\n","    RunnableParallel(\n","        {\n","            \"context\": _search_query | retriever,\n","            \"question\": RunnablePassthrough(),\n","        }\n","    )\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:41:21.807211Z","iopub.status.busy":"2024-10-13T18:41:21.806454Z","iopub.status.idle":"2024-10-13T18:41:24.030451Z","shell.execute_reply":"2024-10-13T18:41:24.029590Z","shell.execute_reply.started":"2024-10-13T18:41:21.807169Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Search query: Which company or institution did Geoffrey Hintion founded?\n"]},{"data":{"text/plain":["'Geoffrey Hinton co-founded the Vector Institute.'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"question\": \"Which company or institution did Geoffrey Hintion founded?\"})"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T18:42:28.529138Z","iopub.status.busy":"2024-10-13T18:42:28.528490Z","iopub.status.idle":"2024-10-13T18:42:29.837912Z","shell.execute_reply":"2024-10-13T18:42:29.837047Z","shell.execute_reply.started":"2024-10-13T18:42:28.529088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Search query: When was Geoffrey Hinton born?\n"]},{"data":{"text/plain":["'Geoffrey Hinton was born on December 6, 1947.'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke(\n","    {\n","        \"question\": \"When was he born?\",\n","        \"chat_history\": [(\"Which company or institution did Geoffrey Hintion founded?\", \"Geoffrey Hinton co-founded the Vector Institute.\")],\n","    }\n",")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5861421,"sourceId":9611111,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
